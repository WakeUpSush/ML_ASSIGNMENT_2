{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9dafb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/mushroom/agaricus-lepiota.data\"\n",
    "\n",
    "columns = [\n",
    "    \"class\", \"cap-shape\", \"cap-surface\", \"cap-color\", \"bruises\", \"odor\",\n",
    "    \"gill-attachment\", \"gill-spacing\", \"gill-size\", \"gill-color\",\n",
    "    \"stalk-shape\", \"stalk-root\", \"stalk-surface-above-ring\",\n",
    "    \"stalk-surface-below-ring\", \"stalk-color-above-ring\",\n",
    "    \"stalk-color-below-ring\", \"veil-type\", \"veil-color\",\n",
    "    \"ring-number\", \"ring-type\", \"spore-print-color\",\n",
    "    \"population\", \"habitat\"\n",
    "]\n",
    "\n",
    "df = pd.read_csv(url, header=None)\n",
    "df.columns = columns\n",
    "\n",
    "#df.to_csv(\"mushroom_dataset.csv\", index=False)\n",
    "\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abe7988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate X and y\n",
    "X = df.drop(\"class\", axis=1)\n",
    "y = df[\"class\"]\n",
    "\n",
    "# Encode y\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder_y = LabelEncoder()\n",
    "y_encoded = label_encoder_y.fit_transform(y)\n",
    "\n",
    "# One-hot encode X (IMPORTANT FIX)\n",
    "X_encoded = pd.get_dummies(X)\n",
    "\n",
    "# Train-test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_encoded, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e031e02",
   "metadata": {},
   "source": [
    "LOGISTIC REGRESSION MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb0cbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_model = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    C=0.1,\n",
    "    solver='liblinear',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "log_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_log = log_model.predict(X_test)\n",
    "\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    matthews_corrcoef,\n",
    "    roc_auc_score\n",
    ")\n",
    "\n",
    "accuracy_log = accuracy_score(y_test, y_pred_log)\n",
    "\n",
    "precision_log = precision_score(y_test, y_pred_log)\n",
    "\n",
    "recall_log = recall_score(y_test, y_pred_log)\n",
    "\n",
    "f1_log = f1_score(y_test, y_pred_log)\n",
    "\n",
    "mcc_log = matthews_corrcoef(y_test, y_pred_log)\n",
    "\n",
    "auc_log = roc_auc_score(y_test, y_pred_log)\n",
    "\n",
    "\n",
    "print(\"Logistic Regression Performance:\")\n",
    "\n",
    "print(\"Accuracy:\", accuracy_log)\n",
    "print(\"Precision:\", precision_log)\n",
    "print(\"Recall:\", recall_log)\n",
    "print(\"F1 Score:\", f1_log)\n",
    "print(\"MCC Score:\", mcc_log)\n",
    "print(\"AUC Score:\", auc_log)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "####### CONFUSION MATRIX\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm_log = confusion_matrix(y_test, y_pred_log)\n",
    "\n",
    "print(cm_log)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa86f7b2",
   "metadata": {},
   "source": [
    "DECISION TREE CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86de12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt_model = DecisionTreeClassifier(\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_dt = dt_model.predict(X_test)\n",
    "\n",
    "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
    "precision_dt = precision_score(y_test, y_pred_dt)\n",
    "recall_dt = recall_score(y_test, y_pred_dt)\n",
    "f1_dt = f1_score(y_test, y_pred_dt)\n",
    "mcc_dt = matthews_corrcoef(y_test, y_pred_dt)\n",
    "auc_dt = roc_auc_score(y_test, y_pred_dt)\n",
    "\n",
    "print(\"Decision Tree Performance:\")\n",
    "print(\"Accuracy:\", accuracy_dt)\n",
    "print(\"Precision:\", precision_dt)\n",
    "print(\"Recall:\", recall_dt)\n",
    "print(\"F1:\", f1_dt)\n",
    "print(\"MCC:\", mcc_dt)\n",
    "print(\"AUC:\", auc_dt)\n",
    "\n",
    "\n",
    "joblib.dump(dt_model, \"models/decision_tree_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab2673d",
   "metadata": {},
   "source": [
    "K-Nearest Neighbors (KNN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c72b6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_knn = knn_model.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "precision_knn = precision_score(y_test, y_pred_knn)\n",
    "recall_knn = recall_score(y_test, y_pred_knn)\n",
    "f1_knn = f1_score(y_test, y_pred_knn)\n",
    "mcc_knn = matthews_corrcoef(y_test, y_pred_knn)\n",
    "auc_knn = roc_auc_score(y_test, y_pred_knn)\n",
    "\n",
    "print(\"KNN Performance:\")\n",
    "print(\"Accuracy:\", accuracy_knn)\n",
    "print(\"Precision:\", precision_knn)\n",
    "print(\"Recall:\", recall_knn)\n",
    "print(\"F1 Score:\", f1_knn)\n",
    "print(\"MCC Score:\", mcc_knn)\n",
    "print(\"AUC Score:\", auc_knn)\n",
    "\n",
    "joblib.dump(knn_model, \"models/knn_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbb8d86",
   "metadata": {},
   "source": [
    "NAIVE BAYES MODEL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336ecde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "nb_model = GaussianNB()\n",
    "\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_nb = nb_model.predict(X_test)\n",
    "\n",
    "accuracy_nb = accuracy_score(y_test, y_pred_nb)\n",
    "precision_nb = precision_score(y_test, y_pred_nb)\n",
    "recall_nb = recall_score(y_test, y_pred_nb)\n",
    "f1_nb = f1_score(y_test, y_pred_nb)\n",
    "mcc_nb = matthews_corrcoef(y_test, y_pred_nb)\n",
    "auc_nb = roc_auc_score(y_test, y_pred_nb)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Naive Bayes Performance:\")\n",
    "\n",
    "print(\"Accuracy:\", accuracy_nb)\n",
    "print(\"Precision:\", precision_nb)\n",
    "print(\"Recall:\", recall_nb)\n",
    "print(\"F1 Score:\", f1_nb)\n",
    "print(\"MCC Score:\", mcc_nb)\n",
    "print(\"AUC Score:\", auc_nb)\n",
    "\n",
    "joblib.dump(nb_model, \"models/naive_bayes_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb0fbd1",
   "metadata": {},
   "source": [
    "RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3de0509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# Random Forest Classifier\n",
    "# ================================\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    matthews_corrcoef,\n",
    "    roc_auc_score\n",
    ")\n",
    "\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "\n",
    "# Step 1: Create Random Forest model\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "\n",
    "# Step 2: Train the model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Step 3: Make predictions\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "\n",
    "# Step 4: Calculate ALL required metrics\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "precision_rf = precision_score(y_test, y_pred_rf)\n",
    "recall_rf = recall_score(y_test, y_pred_rf)\n",
    "f1_rf = f1_score(y_test, y_pred_rf)\n",
    "mcc_rf = matthews_corrcoef(y_test, y_pred_rf)\n",
    "auc_rf = roc_auc_score(y_test, y_pred_rf)\n",
    "\n",
    "\n",
    "# Step 5: Print ALL metrics (Assignment Required Format)\n",
    "print(\"\\n========== Random Forest Performance ==========\")\n",
    "\n",
    "print(f\"Accuracy        : {accuracy_rf:.6f}\")\n",
    "print(f\"Precision       : {precision_rf:.6f}\")\n",
    "print(f\"Recall          : {recall_rf:.6f}\")\n",
    "print(f\"F1 Score        : {f1_rf:.6f}\")\n",
    "print(f\"MCC Score       : {mcc_rf:.6f}\")\n",
    "print(f\"AUC Score       : {auc_rf:.6f}\")\n",
    "\n",
    "print(\"===============================================\")\n",
    "\n",
    "\n",
    "# Step 6: Save model into Git repo models folder\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "joblib.dump(rf_model, \"models/random_forest_model.pkl\")\n",
    "\n",
    "print(\"\\nRandom Forest model saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93145610",
   "metadata": {},
   "source": [
    "XGBOOST MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df983044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================\n",
    "# XGBoost Classifier\n",
    "# =====================================\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    matthews_corrcoef,\n",
    "    roc_auc_score\n",
    ")\n",
    "\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "\n",
    "# Step 1: Create XGBoost model\n",
    "xgb_model = XGBClassifier(\n",
    "    eval_metric='logloss',\n",
    "    random_state=42,\n",
    "    n_estimators=100,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "\n",
    "# Step 2: Train the model\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Step 3: Make predictions\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "\n",
    "# Step 4: Calculate ALL required metrics\n",
    "accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
    "precision_xgb = precision_score(y_test, y_pred_xgb)\n",
    "recall_xgb = recall_score(y_test, y_pred_xgb)\n",
    "f1_xgb = f1_score(y_test, y_pred_xgb)\n",
    "mcc_xgb = matthews_corrcoef(y_test, y_pred_xgb)\n",
    "auc_xgb = roc_auc_score(y_test, y_pred_xgb)\n",
    "\n",
    "\n",
    "# Step 5: Print ALL metrics (Assignment Required)\n",
    "print(\"\\n========== XGBoost Performance ==========\")\n",
    "\n",
    "print(f\"Accuracy        : {accuracy_xgb:.6f}\")\n",
    "print(f\"Precision       : {precision_xgb:.6f}\")\n",
    "print(f\"Recall          : {recall_xgb:.6f}\")\n",
    "print(f\"F1 Score        : {f1_xgb:.6f}\")\n",
    "print(f\"MCC Score       : {mcc_xgb:.6f}\")\n",
    "print(f\"AUC Score       : {auc_xgb:.6f}\")\n",
    "\n",
    "print(\"=========================================\")\n",
    "\n",
    "\n",
    "# Step 6: Save the model to models folder\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "joblib.dump(xgb_model, \"models/xgboost_model.pkl\")\n",
    "\n",
    "print(\"\\nXGBoost model saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3271862",
   "metadata": {},
   "source": [
    "COMPARISION TABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59db434a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create comparison table\n",
    "results = pd.DataFrame({\n",
    "    \"Model\": [\n",
    "        \"Logistic Regression\",\n",
    "        \"Decision Tree\",\n",
    "        \"KNN\",\n",
    "        \"Naive Bayes\",\n",
    "        \"Random Forest\",\n",
    "        \"XGBoost\"\n",
    "    ],\n",
    "    \n",
    "    \"Accuracy\": [\n",
    "        accuracy_log,\n",
    "        accuracy_dt,\n",
    "        accuracy_knn,\n",
    "        accuracy_nb,\n",
    "        accuracy_rf,\n",
    "        accuracy_xgb\n",
    "    ],\n",
    "    \n",
    "    \"Precision\": [\n",
    "        precision_log,\n",
    "        precision_dt,\n",
    "        precision_knn,\n",
    "        precision_nb,\n",
    "        precision_rf,\n",
    "        precision_xgb\n",
    "    ],\n",
    "    \n",
    "    \"Recall\": [\n",
    "        recall_log,\n",
    "        recall_dt,\n",
    "        recall_knn,\n",
    "        recall_nb,\n",
    "        recall_rf,\n",
    "        recall_xgb\n",
    "    ],\n",
    "    \n",
    "    \"F1 Score\": [\n",
    "        f1_log,\n",
    "        f1_dt,\n",
    "        f1_knn,\n",
    "        f1_nb,\n",
    "        f1_rf,\n",
    "        f1_xgb\n",
    "    ],\n",
    "    \n",
    "    \"MCC Score\": [\n",
    "        mcc_log,\n",
    "        mcc_dt,\n",
    "        mcc_knn,\n",
    "        mcc_nb,\n",
    "        mcc_rf,\n",
    "        mcc_xgb\n",
    "    ],\n",
    "    \n",
    "    \"AUC Score\": [\n",
    "        auc_log,\n",
    "        auc_dt,\n",
    "        auc_knn,\n",
    "        auc_nb,\n",
    "        auc_rf,\n",
    "        auc_xgb\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Display table\n",
    "results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c0087b",
   "metadata": {},
   "source": [
    "SAVING RESULTS TO CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446ffd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(\"model_comparison_results.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5591020d",
   "metadata": {},
   "source": [
    "STREAMLIT APP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36627e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "# App title\n",
    "st.title(\"Mushroom Classification App\")\n",
    "\n",
    "st.write(\"Upload a CSV file to predict whether mushrooms are edible or poisonous.\")\n",
    "\n",
    "# Model selection dropdown\n",
    "model_name = st.selectbox(\n",
    "    \"Select Model\",\n",
    "    [\n",
    "        \"Logistic Regression\",\n",
    "        \"Decision Tree\",\n",
    "        \"KNN\",\n",
    "        \"Naive Bayes\",\n",
    "        \"Random Forest\",\n",
    "        \"XGBoost\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Function to load selected model\n",
    "def load_model(name):\n",
    "\n",
    "    if name == \"Logistic Regression\":\n",
    "        return joblib.load(\"models/logistic_regression_model.pkl\")\n",
    "\n",
    "    elif name == \"Decision Tree\":\n",
    "        return joblib.load(\"models/decision_tree_model.pkl\")\n",
    "\n",
    "    elif name == \"KNN\":\n",
    "        return joblib.load(\"models/knn_model.pkl\")\n",
    "\n",
    "    elif name == \"Naive Bayes\":\n",
    "        return joblib.load(\"models/naive_bayes_model.pkl\")\n",
    "\n",
    "    elif name == \"Random Forest\":\n",
    "        return joblib.load(\"models/random_forest_model.pkl\")\n",
    "\n",
    "    elif name == \"XGBoost\":\n",
    "        return joblib.load(\"models/xgboost_model.pkl\")\n",
    "\n",
    "\n",
    "# File uploader\n",
    "uploaded_file = st.file_uploader(\"Upload CSV file\", type=[\"csv\"])\n",
    "\n",
    "if uploaded_file is not None:\n",
    "\n",
    "    # Read uploaded dataset\n",
    "    data = pd.read_csv(uploaded_file)\n",
    "\n",
    "    st.write(\"Uploaded Dataset:\")\n",
    "    st.write(data.head())\n",
    "\n",
    "    # Load model\n",
    "    model = load_model(model_name)\n",
    "\n",
    "    # Apply SAME encoding as training\n",
    "    data_encoded = pd.get_dummies(data)\n",
    "\n",
    "    # Get training columns\n",
    "    training_columns = model.feature_names_in_\n",
    "\n",
    "    # Add missing columns\n",
    "    for col in training_columns:\n",
    "        if col not in data_encoded.columns:\n",
    "            data_encoded[col] = 0\n",
    "\n",
    "    # Ensure correct order\n",
    "    data_encoded = data_encoded[training_columns]\n",
    "\n",
    "    # Predict\n",
    "    predictions = model.predict(data_encoded)\n",
    "\n",
    "    # Add predictions to original dataset\n",
    "    data[\"Prediction\"] = predictions\n",
    "\n",
    "    st.write(\"Prediction Results:\")\n",
    "    st.write(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.10.19)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
